# ETL for Million Songs Dataset for Sparkify
# Documentation contains:
1. Introduction
2. Repository files explained
3. Dataset used
4. The schema Design
5. How to run the project

# Summary of project
## Introduction:

A Fictional Startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

Task is to create a Postgres database with tables designed to optimize queries on song play analysis and create database schema and ETL pipeline for this analysis.

## Repository Files explained


* **[data](data)**: Contains the Data to Perform task on. 
* **[create_tables.py](create_tables.py)**: Connect to Postgres and create, drop tables.
* **[sql_queries.py](sql_queries.py)**: Python script containing SQL-Statements used by create_tables.py and etl.py
* **[etl.py](etl.py)**: Python script to extract the needed information from Data sources and inserting them to the created database schema and tables.
* **[etl.ipynb](etl.ipynb)**: Testing environment to check the dataset structure, data integrity, transformations on a subset of our data and verify the correctness of our pipeline.
* **[test.ipynb](test.ipynb)**: SQL queries to test the data piped into our database.


## Dataset used

1. The first dataset is a subset of real data from the [Million Song Dataset](http://millionsongdataset.com/). Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.

2. The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.


## The Schema design:

### Example of **`songplays` schema**


| Column        | Data Type     | Size  |Constraints|
| ------------- |:-------------:| -----:|:---------:|
| songplay_id   | SERIAL        | -     |primary key|
| start_time    | TIMESTAMP        | -     |      -    |
| user_id   | int        | -     |           |
| level   | text        | -     |           |
| song_id   | varchar        | 26    |           |
| artist_id   | varchar        | 26     |           |
| session_id   | int        | -     |           |
| location   | text        | -     |primary key|
| user_agent   | text        | -     |primary key|


**`users` schema**

| column name | datatype | size | constraint|
|-------------|----------|------|-----------|
| user_id     |int       |-     |primary key|
| first_name  |text      |-     ||
| last_name   |text      |-     ||
| gender      |varchar   |1     ||
| level       |text      |-     ||

**`songs` schema**

| column name | datatype | size | constraint|
|-------------|----------|------|-----------|
| song_id     |varchar   |20    |primary key|
| title       |varchar      |100     ||
| artist_id   |varchar   |20    ||
| year        |integer       |-     ||
| duration    |float     |-     ||

**`artists` schema**

| column name | datatype | size | constraint|
|-------------|----------|------|-----------|
| artist_id   |varchar   |25    |primary key|
| name        |text      |-     ||
| location    |text      |-     ||
| latitude    |float     |-     ||
| longitude   |float     |-     ||

**`time` schema**

| column name | datatype | size | constraint|
|-------------|----------|------|-----------|
| start_time  |bigint    |      |primary key|
| hour        |int       |-     ||
| day         |int       |-     ||
| week        |int       |-     ||
| year        |int       |-     ||
| weekday     |int       |-     ||


* **Fact Table**: songplays
* **Dimension Tables**: users, songs, artists and time.
#### The fact table references the primary keys of each dimention table, enabling joins to songplays on song_id, artist_id, user_id and start_time, respectively. This will enable the analysts to aggregate the data efficiently and explore it using standard SQL queries.

# How to run the python scripts

To create the database tables run the following command:

To create tables:
```bash
python3 create_tables.py
```
Run this below command to fill in the tables via ETL:
```bash
python3 etl.py
```